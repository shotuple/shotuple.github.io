---
layout: post

title: SQLP 3. 데이터베이스 Call과 네트워크 부하

description: > 
  SQLP 자격증 공부

tags:
 - [자격증, SQLP]

toc: true
toc_sticky: true

date: 2022-10-29

sitemap: false

---
---
데이터베이스 Call과 네트워크 부하
===
[출처](https://dataonair.or.kr/db-tech-reference/d-guide/sql/?pageid=2&mod=document&kboard_search_option%5Btree_category_1%5D%5Bkey%5D=tree_category_1&kboard_search_option%5Btree_category_1%5D%5Bvalue%5D=SQL+%EA%B3%A0%EA%B8%89+%ED%99%9C%EC%9A%A9+%EB%B0%8F+%ED%8A%9C%EB%8B%9D&uid=359)

## 1. 데이터베이스 Call 종류
### 가. SQL 커서에 대한 작업 요청에 따른 구분
- Pasrse Call: SQL 파싱을 요청하는 Call
- Excute Call: SQL 실행을 요청하는 Call
- Fetch Call: SELECT문의 결과 데이터 전송을 요청하는 Call
```sql
select cust_nm, birthday 
from customer 
where cust_id = :cust_id 
call count cpu elapsed disk query current rows 
----- ----- ----- ------ ---- ----- ------ -----  
 Parse 1 0.00 0.00 0 0 0 0 Execute 5000 0.18 0.14 0 0  
0 0 Fetch 5000 0.21 0.25 0 20000 0 50000   
----- ----- ----- ------ ---- ----- ------ -----  
   total 10001 0.39 0.40 0 20000 0 50000
```

### 나. Call발생 위치에 따른 구분
- User Call
    - DBMS 외부로부터 요청되는 CALL
    - Peak 시간대에 시스템 확장성을 떨어트리는 가장 큰 요인 중 하나
    - Array Processing을 제대로 지원하지 않는 프레임워크, 화면 페이지 처리에 대한 잘못 설계된 표준가이드, 사용자 정의 함수/프로시저에 대한 무조건적인 제약 등의 경우에서 많이 발생되는 User Call은 성능 저하의 원인, 프로시저 단위 모듈을 지나치게 쪼개서 설계하는 것도 대표적인 예.
- User Call 최소화 방법
    - Loop 쿼리 해소, 집합적 사고로 One SQL
    - Array Processing: Array 단위 Fetch, Bluk Insert/Update/Delete
    - 부분범위처리 원리 활용
    - 효과적인 화면 페이지 처리
    - 사용자 정의 함수/프로시저/트리거의 적절한 활용
- Recursive Call
    - DBMS 내부에서 발생하는 Call
    - SQL 파싱, 최적화 과정에서 발생하는 데이터 딕셔너리 조회, 사용자 정의 함수/프로시저 내에서의 SQL 수행
- Recursive Call 최소화 방법
    - 바인드 변수 사용으로 하드 파싱 최소화
    - 사용자 정의 함수와 프로시저의 시의적절한 사용(무조건 사용하지 못하도록 제약 등)

## 2. 데이터베이스 Call과 성능
### 가. One SQL 구현의 중요성
```java
public class JavaLoopQuery {
     public static void insertData (
         Connection con , String param1 , String param2 , String param3 , long param4) 
         throws Exception {
             String SQLStmt = "INSERT INTO 납입방법별_월요금집계 " + "(고객번호, 납입월, 납입방법코드, 납입금액) " + "VALUES(?, ?, ?, ?)"; 
             PreparedStatement st = con prepareStatement(SQLStmt); 
             st.setString(1, param1); 
             st.setString(2, param2); 
             st.setString(3, param3); 
             st.setLong(4, param4); 
             st.execute(); st.close(); 
             } 
             public static void execute(Connection con, String input_month) 
             throws Exception { 
                WString SQLStmt = "SELECT 고객번호, 납입월, 지로, 자동이체, 신용카드, 핸드폰, 인터넷 " + "FROM 월요금납부실적 " + "WHERE 납입월 = ?"; PreparedStatement 
                stmt = con.prepareStatement(SQLStmt); 
                stmt.setString(1, input_month); 
                ResultSet rs = stmt.executeQuery(); 
                while(rs.next()){
                     String 고객번호 = rs.getString(1); 
                     String 납입월 = rs.getString(2); 
                     long 지로 = rs.getLong(3); 
                     long 자동이체 = rs.getLong(4); 
                     long 신용카드 = rs.getLong(5); 
                     long 핸드폰 = rs.getLong(6); 
                     long 인터넷 = rs.getLong(7); 
                    if(지로 > 0) 
                        insertData (con, 고객번호, 납입월, "A", 지로);
                    if(자동이체 > 0) 
                        insertData (con, 고객번호, 납입월, "B", 자동이체); 
                    if(신용카드 > 0) 
                        insertData (con, 고객번호, 납입월, "C", 신용카드); 
                    if(핸드폰 > 0) 
                        insertData (con, 고객번호, 납입월, "D", 핸드폰); 
                    if(인터넷 > 0) 
                        insertData (con, 고객번호, 납입월, "E", 인터넷); 
                    } 
             rs.close(); 
             Wstmt.close(); 
             } 
             static Connection getConnection() 
             throws Exception { …… } 
             static void releaseConnection(Connection con) 
             throws Exception { …… } 
             public static void main(String[] args) 
             throws Exception{ 
                Connection con = getConnection();
                execute(con, "200903"); 
                releaseConnection(con); 
        } 
    }
```

```java
// 위 프로그램을 아래와 같이 One SQL로 통합하면 최대 110만 번 발생할 수 있는 데이터베이스 Call을 단 2회(Parse Call 1회, Execute Call 1회)로 줄임.

public class JavaOneSQL{ 
    public static void execute(Connection con, String input_month) 
    throws Exception { 
        String SQLStmt = "INSERT INTO 납입방법별_월요금집계" + "(납입월,고객번호,납입방법코드,납입금액) " + "SELECT x.납입월, x.고객번호, CHR(64 + Y.NO) 납입방법코드 " + " , DECODE(Y.NO, 1, 지로, 2, 자동이체, 3, 신용카드, 4, 핸드폰, 5, 인터넷) " + "FROM 월요금납부실적 x, (SELECT LEVEL NO FROM DUAL CONNECT BY LEVEL <= 5) y " + "WHERE x.납입월 = ? " + "AND y.NO IN ( DECODE(지로, 0, NULL, 1), DECODE(자동이체, 0, NULL, 2) " + " , DECODE(신용카드, 0, NULL, 3) , DECODE(핸드폰, 0, NULL, 4) " + " , DECODE(인터넷, 0, NULL, 5) )" ; 
        PreparedStatement stmt = con.prepareStatement(SQLStmt); 
        stmt.setString(1, input_month); 
        stmt.executeQuery(); stmt.close(); 
        } 
        static Connection getConnection() 
        throws Exception { …… } 
        static void releaseConnection(Connection con) 
        throws Exception { …… } 
        public static void main(String[] args) throws Exception{ 
            Connection con = getConnection(); 
            execute(con, "200903"); 
            releaseConnection(con); 
            } 
    }
```

### 나. 데이터베이스 Call과 시스템 확장성
- 데이터베이스 Call은 개별 프로그램의 수행 속도에 큰 영향을 미칠 뿐만 아니라 시스템 전체의 확장성에 영향을 미침.
- 쇼핑몰에서 상품을 찜하는 프로그램을 예로 들어서,  
찜 버튼을 클릭할 때 수행되는 프로그램을 아래처럼 구현했다면 선택한 상품이 5개일 때 메소드도 5번 호출해야 하기때문에 Parse Call과 Execute Call이 각각 5번씩 발생한다.

```java
void insertWishList ( String p_custid , String p_goods_no ) { 
    SQLStmt = "insert into wishlist " + "select custid, goods_no " + "from cart " + "where custid = ? " + "and goods_no = ? " ; 
    stmt = con.preparedStatement(SQLStmt); 
    stmt.setString(1, p_custid); 
    stmt.setString(2, p_goods_no); 
    stmt.execute(); 
    }

// 반면, 아래와 같이 구현했다면 메소드를 1번만 호출하기 때문에 Parse Call과 Execute Call도 각각 한번씩만 발생. 
// 단적으로, 24시간 내내 이 프로그램만 수행된다면 시스템이 5배의 확장성을 갖는 것이며, 
// AP 설계가 DBMS 성능을 좌우하는 매우 중요한 요인임을 보여줌.

void insertWishList ( String p_custid , String[] p_goods_no ) {
     SQLStmt = "insert into wishlist " + "select custid, goods_no " + "from cart " + "where custid = ? " + "and goods_no in ( ?, ?, ?, ?, ? )" ; 
     stmt = con.preparedStatement(SQLStmt); 
     stmt.setString(1, p_custid); 
     for(int i=0; i < 5; i++)
        { 
        stmt.setString(i+2, p_goods_no[i]); 
        } 
    stmt.execute(); }

```

## 3. Array Processing 
- Array Processing 기능으로 한 번의 SQL 수행으로 다량의 레코드를 동시에 처리. 이는 네트워크를 통한 데이터베이스 Call을 줄여 SQL 수행시간과 CPU 사용량을 획기적으로 줄임. 
- 앞서 본 '납입방법별_월요금집계' 테이블 가공 사례에 Array Processing 기법을 적용한 코드
```java
1 public class JavaArrayProcessing{ 
2 public static void insertData( Connection con 
3 , PreparedStatement st 
4 , String param1 
5 , String param2 
6 , String param3 
7 , long param4) 
throws Exception{ 
    8 st.setString(1, param1);
    9 st.setString(2, param2); 
    10 st.setString(3, param3); 
    11 st.setLong(4, param4); 
    12 st.addBatch(); 
    13 } 
    14 
    15 public static void execute(Connection con, String input_month) 
    16 throws Exception { 
        17 long rows = 0; 
        18 String SQLStmt1 = "SELECT 고객번호, 납입월" 
        19 + ", 지로, 자동이체, 신용카드, 핸드폰, 인터넷 " 
        20 + "FROM 월요금납부실적 " 
        21 + "WHERE 납입월 = ?"; 
        22 
        23 String SQLStmt2 = "INSERT INTO 납입방법별_월요금집계 " 
        24 + "(고객번호, 납입월, 납입방법코드, 납입금액) " 
        25 + "VALUES(?, ?, ?, ?)"; 
        26 
        27 con.setAutoCommit(false);
        28 
        29 PreparedStatement stmt1 = con.prepareStatement(SQLStmt1); 
        30 PreparedStatement stmt2 = con.prepareStatement(SQLStmt2); 
        31 stmt1.setFetchSize(1000); 
        32 stmt1.setString(1, input_month); 
        33 ResultSet rs = stmt1.executeQuery(); 
        34 while(rs.next()){ 
        35 String 고객번호 = rs.getString(1); 
        36 String 납입월 = rs.getString(2); 
        37 long 지로 = rs.getLong(3); 
        38 long 자동이체 = rs.getLong(4); 
        39 long 신용카드 = rs.getLong(5); 
        40 long 핸드폰 = rs.getLong(6); 
        41 long 인터넷 = rs.getLong(7); 
        42 
        43 if(지로 > 0) 
        44 insertData (con, stmt2, 고객번호, 납입월, "A", 지로); 
        45 
        46 if(자동이체 > 0) 
        47 insertData (con, stmt2, 고객번호, 납입월, "B", 자동이체); 
        48 
        49 if(신용카드 > 0) 
        50 insertData (con, stmt2, 고객번호, 납입월, "C", 신용카드); 
        51 
        52 if(핸드폰 > 0) 
        53 insertData (con, stmt2, 고객번호, 납입월, "D", 핸드폰); 
        54 
        55 if(인터넷 > 0) 
        56 insertData (con, stmt2, 고객번호, 납입월, "E", 인터넷); 
        57 
        58 if(++rows%1000 == 0) stmt2.executeBatch(); 
        59 
        60 } 
        61 
        62 rs.close(); 
        63 stmt1.close(); 
        64 
        65 stmt2.executeBatch(); 
        66 stmt2.close(); 
        67 
        68 con.commit(); 
        69 con.setAutoCommit(true); 
        70 } 
        71 
        72 static Connection getConnection() throws Exception { } 
        73 static void releaseConnection(Connection con) throws Exception { …… } 
        74 
        75 public static void main(String[] args) throws Exception{ 
            76 Connection con = getConnection(); 
            77 execute(con, "200903"); 
            78 releaseConnection(con); 
            79 } 
        80 }
```
- INSERT할 데이터를 계속 Array에 담다가(12번) 1,000건 쌓일 때마다 한 번씩 executeBatch를 수행(58번)
- SELECT 결과집합을 Fetch 할 때 1,000개 단위로 Fetch하도록 조정(31번)
- 위 프로그램을 수행하면 One SQL로 구현할 때와 비슷한 속도를 보임. -One SQL로 통합했을 때 나타나는 극적인 성능개선 효과가 데이터베이스 Call 횟수를 줄이는 데 있음을 여기서도 알 수 있다.
- 대용량 데이터를 처리하는 데 Array Processing은 필수적인데, 연속된 일련의 처리과정이 모두 Array 단위로 진행 시 효과 극대화.
    - 이를테면, Array 단위로 수천 건씩 아무리 빠르게 Fetch 하더라도 다음 단계에서 수행할 INSERT가 건건이 처리된다면 그 효과가 크게 반감되며, 반대의 경우도 마찬가지임.

- PL/SQL로 데이터를 Bulk로 1,000건씩 Fetch해서 Bulk로 INSERT하는 예제
```sql
DECLARE l_fetch_size 
NUMBER DEFAULT 1000; -- 1,000건씩 Array 처리 
CURSOR c IS SELECT empno, ename, job, sal, deptno, hiredate 
FROM emp; … BEGIN OPEN C; 
LOOP FETCH c BULK COLLECT INTO p_empno, p_ename, p_job, p_sal, p_deptno, p_hiredate 
LIMIT l_fetch_size; 
FORALL i IN p_empno.first..p_empno.last 
INSERT INTO emp2 VALUES ( p_empno (i) , p_ename (i) , p_job (i) , p_sal (i) , p_deptno (i) , p_hiredate (i) ); 
EXIT WHEN c%NOTFOUND; 
END LOOP; 
CLOSE C;
```
- Array Processing 기법을 지원하는 인터페이스가 개발 언어마다 다르므로 API 확인 후 활용.

## 4. Fetch Call 최소화
### 가. 부분범위처리 원리
- 사용자로부터 Fetch Call이 있을 때마다 일정량씩 나누어 전송하는 것 = 부분범위처리
![image](https://user-images.githubusercontent.com/105637541/198826624-db72163b-43ee-493e-9b28-9e76e5d4223d.png)
- Fetch Call이 있을 때만 벽돌을 실어 나름. 추가 요청이 없으면 운반작업은 거기서 멈춤.
- DBMS도 이처럼 데이터를 클라이언트에게 전송할 때 일정량씩 나누어 전송한다.
- Oracle의 경우 ArraySize(또는 FetchSize) 설정을 통해 운반단위를 조절할 수 있다.
```sql
set arraysize 100

call count cpu elapsed 
disk query current rows 
----- ---- ----- ------ ----- ----- ----- ------ 
Parse 1 0.00 0.00 0 0 0 0 Execute 1 0.00 0.02 2 2 0 0 Fetch 301 0.14 0.18 9 315 0 30000 
----- ---- ----- ------ ----- ----- ----- ------ 
total 303 0.14 0.20 11 317 0 30000
```

- 30,000개 로우를 읽기 위해 Fetch Call이 301번 발생한 것을 보고 ArraySize가 100으로 설정된 상태에서 수행된 쿼리인 것을 짐작 가능.
- SQL Server의 경우 네트워크 패키지 크기로 운반단위를 조절하는데, 쿼리 분석기 옵션에서 네트워크 패키지 크기 항목을 보면 기본 값이 4,096 바이트로 설정된 것을 확인 가능.
- Oracle의 경우 Array 크기의 데이터를 내부적으로 SDU(Session Data Unit, Session 레이어), TDU(Transport Data Unit, Transport 레이어) 단위로 나누어 전송.
- ArraySize를 작게 설정하면 하나의 네트워크 패킷에 담아 전송하지만, 크게 설정하면 여러 개 패킷으로 나누어 전송.
- 전체 결과집합 중 아직 전송하지 않은 분량이 많이 남아있어도 클라이언트로부터 Fetch Call을 받기 전까지 서버는 멈춰서 기다린다.
- OLTP성 업무에서는 쿼리 결과집합이 아주 많아도 그 중 일부만 Fetch해서 보여주고 멈춰도 되는 업무가 많음.
    - 수천 수만 건을 일일이 데이터를 보는 사용자는 거의 없음.
    - 사용자가 '다음' 버튼을 클릭하거나 스크롤을 내릴 때만 추가적인 Fetch Call로 필요한 만큼 더 가져옴.
    - 출력 대상 레코드가 많을수록 Array를 빠르게 채움. -잘 설계된 인덱스와 부분범위처리 방식을 이용해 대용량 OLTP 환경에서 극적인 성능개선 효과를 얻을 수 있는 원리.
    - 출력 대상 레코드가 많을수록 응답 속도가 빨라지는 것은 부분범위처리가 가능한 업무에만 해당. -결과집합 전체를 Fetch 하는 DW/OLAP성 업무나 서버 내에서 데이터를 가공하는 프로그램에선 결과집합이 많을수록 더 빨라지는 일은 없음.
    >DBMS 서버가 부분범위처리 방식으로 데이터를 전송하는데 어떤 개발팀은 결과를 모두 Fetch 하고서야 출력을 시작하도록 개발.
    또 어떤 개발팀은 첫 화면부터 빠르게 출력하지만 사용자의 명시적인 Fetch 요청이 없어도 백그라운드에서 계속 Fetch Call을 일으켜 클라이언트 캐시에 버퍼링하도록 개발.
    SQL Server 개발 환경에서 가장 많이 사용되는 쿼리 분석기의 Grid 모드가 전자에 해당.
    이것은 쿼리 툴의 특성일 뿐이며, 모든 DBMS는 데이터를 일정량씩 나누어 전송.
    불필요한 데이터베이스 Call과 네트워크 부하를 일으켜선 결코 고성능 데이터베이스 애플리케이션을 구축하기 힘듬. 

### 나. ArraySize 조정에 의한 Fetch Call 감소 및 블록 I/O 감소 효과
- 네트워크를 통해 전송해야 할 데이터량에 따라 ArraySize를 조절할 필요가 있음.
- 대량 데이터라면 값을 크게 해서 Fetch Call 횟수를 줄임.  
반대로 앞쪽 일부분 데이터만 Fetch하다 멈추는 프로그램이라면 ArraySize를 작게 설정하는 것이 유리함.
- ArraySize를 증가시키면 네트워크 부하와 서버 프로세스가 읽어야 할 블록 개수가 줄어듬.
![image](https://user-images.githubusercontent.com/105637541/198827634-533ec7d7-673d-43d0-a763-676151b7ad2b.png)
- ArraySize가 3일 경우, Fetch 횟수는 10, 블록 I/O는 12
- ArraySize가 10일 경우, Fetch 횟수는 3, 블록 I/O는 3
![image](https://user-images.githubusercontent.com/105637541/198827701-fad9d46f-bddb-47a1-bfba-9b7b8aa4da5a.png)
- ArraySize를 키운다고 Fetch Count와 블록 I/O가 같은 비율로 줄어들지 않음.
- 무작정 크다고 좋은 것은 아니며 일정 크기 이상에선 리소스 낭비.
- Oracle PL/SQL에서 커서를 열고 레코드를 Fetch 하면, (3항 Array Processing에서 보았던 Bulk Collect 구문을 사용하지 않는 한) 9i까지는 한 번에 한 로우씩만 처리(Single-Row Fetch).  
10g부터는 자동으로 100개씩 Array Fetch가 일어나지만, 아래 처럼 커서의 Open, Fetch, Close가 내부적으로 이루어지는 Cursor FOR Loop 구문을 이용할 때만 작동한다는 사실을 기억하기 바란다.
for item in cursor loop …… end loop;
```java
// java ArraySize 조정
String sql = "select custid, name from customer"; PreparedStatement stmt = conn.prepareStatement(sql); stmt.setFetchSize(100); 
// Statement에서 조정 
ResultSet rs = stmt.executeQuery(); 
// rs.setFetchSize(100); -- ResultSet에서 조정할 수도 있다. 
while( rs.next() ) {
     int empno = rs.getInt(1); 
     String ename = rs.getString(2); 
     System.out.println(empno + ":" + ename); } 
rs.close(); 
stmt.close();
// FetchSize가 100일 때 Fetch 메커니즘
// 최초 rs.next() 호출 시 100건을 가져와서 클라이언트 Array 버퍼에 캐싱.
// 이후 rs.next() 호출 시 데이터베이스 Call이 아닌 Array 버퍼에서 읽음.
// 버퍼에 캐싱된 데이터를 모두 소진한 후 101번째 rs.next() 호출 시 다시 100건을 가져옴.
// 모든 결과집합을 다 읽을 때까지 2~3번 과정 반복.
```

## 5. 페이지 처리 활용
- 부분범위처리를 이용한 대용량 온라인 조회 성능 개선은 커서를 닫지 않은 상태에서 사용자가 명시적으로 요청(스크롤을 내리거나 '다음' 버튼 클릭 등)할 때만 데이터를 Fetch 할 수 있는 개발환경에서 가능.
- 사용문 수행 방식, 페이지 처리 구현
```sql
void pagination(ResultSet rs, long pageNo, int pageSize) 
throws Exception { int i = 0 ;
 while( rs.next() ) { i
    f(++i > (pageNo-1)*pageSize) printRow(rs); 
    if(i == pageNo * pageSize) 
        break; } }
```
- 사용자가 새로운 페이지 출력을 요청할 때마다 SQL 수행.  
매번 첫 레코드부터 읽어서 출력해야할 페이지(pageNo)에 도달하면 printRow 호출.  
printRow를 pageSize개수만큼 호출하고 Fetch 정지.  
- 뒤 페이지로 이동할수록 많은 Fetch Call을 유발할 것이고, 전반적으로 이런 패턴으로 구현했다면 시스템에 얼마나 악영향을 끼칠지 어렵지 않게 짐작 가능. -> 페이지 처리를 서버 단에서 완료하고 최종 출력 레코드만 Fetch 하도록 수정해야함.
- 페이지 처리를 하지 않았을 때 발생하는 부하요인
    - 다량 발생하는 Fetch Call
    - 대량의 결과 집합을 전송하면서 발생하는 네트워크 부하
    - 대량의 데이터 블록을 읽으면서 발생하는 I/O 부하
    - AP 서버 및 웹 서버 리소스 사용량 증가
- 이렇게 여러가지 부하를 일으키지만 정작 사용자는 앞쪽 일부 데이터만 보고 업무처리를 완료하는 경우가 대부분.  
쿼리 자체의 성능도 문제지만 시스템 전반에 걸친 불필요한 리소스 낭비가 더 큰 문제.
- 부하를 해소하는 페이지 처리
    - 페이지 단위로 필요한 만큼만 Fetch Call
    - 페이지 단위로 필요한 만큼만 네트워크 전송.
    - 인덱스와 부분범위처리 원리로 각 페이지에 필요한 최소량만 I/O
    - 데이터를 소량씩 나누어 전송하므로 AP웹 서버 리소스 사용량 최소화
- 결론적으로, 조회할 데이터가 일정량 이상이고 수행빈도가 높다면 필수적으로 페이지 처리 구현 -효과적인 페이지 처리 구현 방안은 5장 고급 SQL 튜닝에서

## 6. 분산 쿼리
- 부하 분산, 재해 복구, 보안 등 여러 목적으로 분산 환경의 DB를 구축.
- 분산 쿼리 성능 문제 -특히 원격 조인

분산 DB 간 테이블 조인 성능을 높일 방안
```sql
select channel_id, sum(quantity_sold) auantity_cold from order a, sales@lk_sales b 
where a.order_date between :1 and :2 and b.order_no = a.order_no 
group by channel_id Rows Row Source Operation 
----- --------------------------------------------- 5 SORT GROUP BY 10981 NESTED LOOPS 500000 REMOTE 10981 TABLE ACCESS BY INDEX ROWID ORDER 500000 INDEX UNIQUE SCAN (ORDER_PK)
```
- 원격(Remote)에 있는 sales 테이블을 전송받아 order 테이블과 NL 방식으로 조인. -sales 데이터를 네트워크를 통해 전송받으니 쿼리 성능이 나쁨.
- 조건에 해당하는 데이터만 원격으로 보내서 조인과 group by를 거친 결과집합만 전송받으면 큰 성능개선 가능.

원격 서버가 쿼리를 처리하도록 driving_site 힌트를 지정하고 수행한 결과
```sql
select /*+ driving_site(b) */ channel_id, sum(quantity_sold) auantity_cold 
from order a, sales@lk_sales b 
where a.order_date between :1 and :2 and b.order_no = a.order_no 
group by channel_id Rows Row Source Operation 
---- --------------------------------------------- 5 SORT GROUP BY 10981 NESTED LOOPS 939 TABLE ACCESS (BY INDEX ROWID) OF ‘ORDER’ 939 INDEX (RANGE SCAN) OF ‘ORDER_IDX2’ (NON-UNIQUE) 10981 REMOTE
```
- 인덱스를 이용해 939건의 order 데이터를 읽어 원격으로 보냈고, 거기서 처리가 완료된 5건만 전송받음. 
- 분산 쿼리 성능 핵심 원리는 네트워크를 통한 데이터 전송량 최소화!

## 7. 사용자 정의 함수/프로시저의 특징과 성능
- 일반 프로그래밍 언어에서는 반복적으로 사용되는 소스 코드를 함수로써 모듈화하는 것을 권장함. 그러나 DBMS 내부에서 수행되는 사용자 정의 함수/프로시저를 그런 용도로 사용한다면 성능때문에 낭패를 볼 수 있음.

### 가. 사용자 정의 함수/프로시저의 특징
- 사용자 정의 함수/프로시저는 내장함수처럼 Native 코드로 완전 컴파일된 형태가 아니어서 가상머신 같은 별도의 실행엔진을 통해 실행된다. 실행될 때마다 컨텍스트 스위칭이 일어나며, 이로 인해 내장함수에 비해 성능이 떨어짐.
```sql
create or replace function date_to_char(p_dt date) return varchar2 as begin return to_char(p_dt, 'yyyy/mm/dd hh24:mi:ss'); 
end; /
-- to_char 함수에 비해 5~10배 가량 느려짐
```
- 게다가, 메인 쿼리가 참조하는 사용자 정의 함수에 또 다른 쿼리문이 내장돼 있으면 수행 성능이 훨씬 나빠짐. -함수에 내장된 쿼리를 수행할 때마다 Execute Call, Fetch Call이 재귀적으로 일어나기 때문.  
Recursive Call이 반복적으로 일어나는 것이며, Parse Call은 처음 수행할 때 한 번 일어남.  
네트워크를 경유하는 User Call에 비해 Recursive Call의 성능 부하는 미미하지만, 그 횟수가 무수히 반복되면 성능이 크게 떨어짐.

### 나. 사용자 정의 함수/프로시저에 의한 성능 저하 해소 방안
- 대용량 조회 쿼리에서 함수를 남용하면 읽는 레코드 수만큼 함수 호출과 Recursive Call이 반복돼 성능이 나빠짐.
- 사용자 정의 함수는 소량의 데이터를 조회할 때 혹은 부분범위처리가 가능한 상황에서 제한적으로 사용. 성능을 위해서라면 가급적 조인 또는 스칼라 서브쿼리 형태로 변환.

- - -
# +Note
- BULK COLLECT
- FORALL